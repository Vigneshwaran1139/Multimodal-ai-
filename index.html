import React, { useState, useRef } from 'react';
import { Camera, Mic, Image as ImageIcon, Send, Loader2, X, FileText } from 'lucide-react';

export default function MultimodalAIAssistant() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [selectedImage, setSelectedImage] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  const fileInputRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  const handleImageUpload = (e) => {
    const file = e.target.files[0];
    if (file && file.type.startsWith('image/')) {
      const reader = new FileReader();
      reader.onload = (event) => {
        setSelectedImage({
          url: event.target.result,
          file: file
        });
      };
      reader.readAsDataURL(file);
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data);
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        processAudioInput(audioUrl, audioBlob);
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error('Error accessing microphone:', error);
      alert('Could not access microphone. Please check permissions.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  const processAudioInput = async (audioUrl, audioBlob) => {
    const userMessage = {
      id: Date.now(),
      type: 'user',
      content: 'ðŸŽ¤ Voice message',
      audioUrl: audioUrl,
      timestamp: new Date().toLocaleTimeString()
    };
    
    setMessages(prev => [...prev, userMessage]);
    await processWithAI('Transcribe and respond to this audio message', null, audioBlob);
  };

  const processWithAI = async (text, image, audio) => {
    setIsLoading(true);
    
    try {
      let userContent = [];
      
      if (image) {
        userContent.push({
          type: "image",
          source: {
            type: "base64",
            media_type: image.file.type,
            data: image.url.split(',')[1]
          }
        });
      }
      
      userContent.push({
        type: "text",
        text: text || "Please analyze this input and provide insights."
      });

      const response = await fetch("https://api.anthropic.com/v1/messages", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "claude-sonnet-4-20250514",
          max_tokens: 1000,
          messages: [
            {
              role: "user",
              content: userContent
            }
          ],
        })
      });

      const data = await response.json();
      const aiResponse = data.content
        .filter(item => item.type === "text")
        .map(item => item.text)
        .join("\n");

      const aiMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: aiResponse,
        timestamp: new Date().toLocaleTimeString()
      };

      setMessages(prev => [...prev, aiMessage]);
    } catch (error) {
      console.error('AI API Error:', error);
      const errorMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: 'Sorry, I encountered an error processing your request. Please try again.',
        timestamp: new Date().toLocaleTimeString()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!input.trim() && !selectedImage) return;

    const userMessage = {
      id: Date.now(),
      type: 'user',
      content: input || 'Analyze this image',
      image: selectedImage?.url,
      timestamp: new Date().toLocaleTimeString()
    };

    setMessages(prev => [...prev, userMessage]);
    
    await processWithAI(input, selectedImage, null);
    
    setInput('');
    setSelectedImage(null);
  };

  const clearImage = () => {
    setSelectedImage(null);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  return (
    <div className="flex flex-col h-screen bg-gradient-to-br from-blue-50 to-indigo-100">
      {/* Header */}
      <div className="bg-white shadow-md px-6 py-4 border-b-2 border-indigo-200">
        <h1 className="text-3xl font-bold text-indigo-600 flex items-center gap-2">
          <Camera className="w-8 h-8" />
          Multimodal AI Assistant
        </h1>
        <p className="text-sm text-gray-600 mt-1">Chat with text, images, and voice</p>
      </div>

      {/* Messages Area */}
      <div className="flex-1 overflow-y-auto px-6 py-4 space-y-4">
        {messages.length === 0 && (
          <div className="text-center mt-20">
            <div className="inline-block p-6 bg-white rounded-2xl shadow-lg">
              <FileText className="w-16 h-16 mx-auto text-indigo-400 mb-4" />
              <h2 className="text-xl font-semibold text-gray-700 mb-2">Start a Conversation</h2>
              <p className="text-gray-500">Send text, upload images, or record voice messages</p>
            </div>
          </div>
        )}
        
        {messages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div
              className={`max-w-2xl rounded-2xl px-5 py-3 shadow-md ${
                message.type === 'user'
                  ? 'bg-indigo-500 text-white'
                  : 'bg-white text-gray-800'
              }`}
            >
              {message.image && (
                <img
                  src={message.image}
                  alt="Uploaded"
                  className="rounded-lg mb-2 max-w-sm"
                />
              )}
              {message.audioUrl && (
                <audio controls src={message.audioUrl} className="mb-2 w-full" />
              )}
              <p className="whitespace-pre-wrap">{message.content}</p>
              <span className={`text-xs mt-1 block ${
                message.type === 'user' ? 'text-indigo-200' : 'text-gray-500'
              }`}>
                {message.timestamp}
              </span>
            </div>
          </div>
        ))}
        
        {isLoading && (
          <div className="flex justify-start">
            <div className="bg-white rounded-2xl px-5 py-3 shadow-md">
              <Loader2 className="w-5 h-5 animate-spin text-indigo-500" />
            </div>
          </div>
        )}
      </div>

      {/* Input Area */}
      <div className="bg-white border-t-2 border-indigo-200 px-6 py-4">
        {selectedImage && (
          <div className="mb-3 relative inline-block">
            <img
              src={selectedImage.url}
              alt="Selected"
              className="h-20 rounded-lg border-2 border-indigo-300"
            />
            <button
              onClick={clearImage}
              className="absolute -top-2 -right-2 bg-red-500 text-white rounded-full p-1 hover:bg-red-600"
            >
              <X className="w-4 h-4" />
            </button>
          </div>
        )}
        
        <form onSubmit={handleSubmit} className="flex gap-2">
          <input
            type="file"
            ref={fileInputRef}
            onChange={handleImageUpload}
            accept="image/*"
            className="hidden"
          />
          
          <button
            type="button"
            onClick={() => fileInputRef.current?.click()}
            className="p-3 bg-indigo-100 text-indigo-600 rounded-xl hover:bg-indigo-200 transition"
            title="Upload Image"
          >
            <ImageIcon className="w-5 h-5" />
          </button>
          
          <button
            type="button"
            onClick={isRecording ? stopRecording : startRecording}
            className={`p-3 rounded-xl transition ${
              isRecording
                ? 'bg-red-500 text-white animate-pulse'
                : 'bg-indigo-100 text-indigo-600 hover:bg-indigo-200'
            }`}
            title={isRecording ? 'Stop Recording' : 'Record Voice'}
          >
            <Mic className="w-5 h-5" />
          </button>
          
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            placeholder="Type your message..."
            className="flex-1 px-4 py-3 border-2 border-gray-300 rounded-xl focus:outline-none focus:border-indigo-500"
            disabled={isLoading}
          />
          
          <button
            type="submit"
            disabled={isLoading || (!input.trim() && !selectedImage)}
            className="p-3 bg-indigo-500 text-white rounded-xl hover:bg-indigo-600 disabled:bg-gray-300 disabled:cursor-not-allowed transition"
          >
            <Send className="w-5 h-5" />
          </button>
        </form>
      </div>
    </div>
  );
}